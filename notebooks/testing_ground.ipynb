{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "298b199f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chex import assert_rank\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap, jit, grad\n",
    "import jax\n",
    "import optax\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "30044bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tinyshakespeareloader.hamlet import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8f7d121b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleBigram(hk.Module):\n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super(SimpleBigram, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        assert_rank(x, 2)\n",
    "        logits = hk.Embed(vocab_size=self.vocab_size, embed_dim=self.vocab_size)(x)\n",
    "        assert_rank(logits, 3)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bb564e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data(batch_size=32)\n",
    "dummy_x, dummy_y = next(iter(data[\"train_dataloader\"]))\n",
    "vocab_size = data[\"vocabulary_size\"]\n",
    "def bigram_forward(x):\n",
    "    return SimpleBigram(vocab_size)(x)\n",
    "model = hk.transform(bigram_forward)\n",
    "params = model.init(rng=next(hk.PRNGSequence(42)), x=dummy_x.numpy())\n",
    "dummy_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8505992b-7542-4726-b242-139e1396e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = lambda params, x, rng: model.apply(params=params, x=x, rng=next(rng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "973b65d8-be33-425f-aab1-5078231004f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0.0%, loss_value=Array(2.6456897, dtype=float32)\n",
      "step=9.999681234260942%, loss_value=Array(2.0665283, dtype=float32)\n",
      "step=19.999362468521884%, loss_value=Array(2.2822242, dtype=float32)\n",
      "step=29.999043702782824%, loss_value=Array(2.519982, dtype=float32)\n",
      "step=39.99872493704377%, loss_value=Array(2.3446436, dtype=float32)\n",
      "step=49.99840617130471%, loss_value=Array(2.5622246, dtype=float32)\n",
      "step=59.99808740556565%, loss_value=Array(2.11761, dtype=float32)\n",
      "step=69.9977686398266%, loss_value=Array(2.3336637, dtype=float32)\n",
      "step=79.99744987408754%, loss_value=Array(2.4252636, dtype=float32)\n",
      "step=89.99713110834847%, loss_value=Array(2.1375194, dtype=float32)\n",
      "step=99.99681234260942%, loss_value=Array(3.441904, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def loss_fn(params: optax.Params, batch: jnp.ndarray, labels: jnp.ndarray) -> jnp.ndarray:\n",
    "    rng_key = hk.PRNGSequence(42)\n",
    "    output = net(params, batch, rng_key)\n",
    "    # output = model.apply(params=params, x=batch, rng=next(rng_key))\n",
    "    loss_value = optax.softmax_cross_entropy_with_integer_labels(output, labels)\n",
    "    return loss_value.mean()\n",
    "\n",
    "@jit\n",
    "def step(params, opt_state, batch, labels):\n",
    "    loss_value, grads = jax.value_and_grad(loss_fn)(params, batch, labels)\n",
    "    updates, opt_state = optim.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss_value\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optim = optax.adamw(learning_rate=learning_rate)\n",
    "def fit(params: optax.Params, optim: optax.GradientTransformation, train_dataloader: DataLoader):\n",
    "    opt_state = optim.init(params)\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_dataloader):\n",
    "        with jax.checking_leaks():\n",
    "            params, opt_state, loss_value = step(params, opt_state, x.numpy(), y.numpy())\n",
    "        if i % (len(train_dataloader) // 10) == 0:\n",
    "            print(f\"step={(i / len(train_dataloader)) * 100}%, {loss_value=}\")\n",
    "    return params\n",
    "\n",
    "params = fit(params, optim, train_dataloader=data[\"train_dataloader\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "92162363-4cae-4d5b-aaa4-43a09af346f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWetis'shyst ase say\\nWhr tow.\\nANe,\\nEreroneisa, shisthadove, a banod\\nINartilos han'shios w; tin, 't s\""
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def blabber(params, max_new_tokens=100):\n",
    "    rng = hk.PRNGSequence(42)\n",
    "    idx = jnp.zeros(shape=(1, 1), dtype=jnp.int32)\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        output = net(params=params, x=idx, rng=n))\n",
    "        output = output[:, -1, :]\n",
    "        next_idx = jax.random.categorical(next(rng), output).reshape(-1,1)        \n",
    "        idx = jnp.concatenate((idx, next_idx), axis=1)\n",
    "\n",
    "    return idx\n",
    "idx = blabber(params)\n",
    "\n",
    "decode = data[\"decode\"]\n",
    "decode(idx[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539978b-9401-4137-af2f-d0c583e5c51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
